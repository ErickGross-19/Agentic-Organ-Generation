{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single Agent Organ Generator V2\n",
    "\n",
    "This notebook provides a comprehensive demonstration of the Single Agent Organ Generator V2 workflow, featuring the adaptive Rule Engine for intelligent requirements capture.\n",
    "\n",
    "## Key Features\n",
    "\n",
    "| Feature | Description |\n",
    "|---------|-------------|\n",
    "| **Adaptive Rule Engine** | Intelligent questioning based on missing information, ambiguous language, and feasibility constraints |\n",
    "| **Three Rule Families** | Completeness (A), Ambiguity (B), and Conflict (C) rules |\n",
    "| **Resolution Strategy** | Three-tier approach: Infer from text, propose defaults, ask targeted questions |\n",
    "| **Question Prioritization** | Questions ranked by rework cost to minimize iteration |\n",
    "| **Organ-Specific Variants** | Tailored questions for liver, kidney, lung, heart, and generic structures |\n",
    "| **Multi-Object Support** | Generate multiple structures per project with independent workflows |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0afcd8a",
   "metadata": {},
   "source": [
    "## Important: Execution Modes\n",
    "\n",
    "Understanding the available execution modes is essential for effective use of this workflow.\n",
    "\n",
    "| Mode | Description | Recommended Use Case |\n",
    "|------|-------------|---------------------|\n",
    "| **Prompt-only** (default) | LLM returns text responses without code execution | Planning, prototyping, specification generation |\n",
    "| **Execution-enabled** | LLM-generated code runs in a sandboxed environment | Testing with controlled output |\n",
    "| **Spec-only** (recommended) | LLM produces structured specification; Python executes generation locally | Production workflows |\n",
    "\n",
    "**Note:** By default, `AgentRunner` has `auto_execute_code=False`. The LLM describes intended actions but does not create files. For production use, we recommend the spec-only approach where the LLM produces a structured specification and Python executes generation locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.insert(0, os.path.abspath(\"..\"))\n",
    "from automation import (\n",
    "    SingleAgentOrganGeneratorV2, WorkflowState, ProjectContext, ObjectContext,\n",
    "    ObjectRequirements, QUESTION_GROUPS, ORGAN_QUESTION_VARIANTS,\n",
    "    detect_organ_type, get_tailored_questions, run_single_agent_workflow,\n",
    "    # Rule Engine components\n",
    "    RuleEngine, IntentParser, QuestionPlanner,\n",
    "    RuleFlag, ProposedDefault, RuleEvaluationResult, PlannedQuestion,\n",
    "    run_rule_based_capture,\n",
    ")\n",
    "print(\"All imports successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configuration\n",
    "\n",
    "Configure the LLM provider and model for the workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "API_KEY = os.environ.get('OPENAI_API_KEY', None)\n",
    "PROVIDER = 'openai'\n",
    "MODEL = 'gpt-4'\n",
    "print(f'Provider: {PROVIDER}, Model: {MODEL}, API Key: {API_KEY is not None}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Rule Engine\n",
    "\n",
    "The workflow employs an adaptive rule engine that intelligently determines which questions to ask. Rather than presenting a fixed sequence of questions, the rule engine evaluates:\n",
    "\n",
    "1. **Missing Information** (Family A - Completeness): Required fields that must be populated\n",
    "2. **Ambiguous Language** (Family B - Ambiguity): Terms that require clarification\n",
    "3. **Feasibility Issues** (Family C - Conflict): Specifications that would fail or produce impractical results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 IntentParser\n",
    "\n",
    "The IntentParser extracts explicit values from user text and detects ambiguities that require clarification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test IntentParser with different intents\n",
    "test_intents = [\n",
    "    'box 2x6x3 cm with diameter 1mm',\n",
    "    'dense liver-like network with inlet on the left side',\n",
    "    'symmetric branching with 2 inlets',\n",
    "    'perfusion network for tissue engineering',\n",
    "]\n",
    "\n",
    "print('IntentParser Analysis:')\n",
    "print('=' * 70)\n",
    "for intent in test_intents:\n",
    "    parser = IntentParser(intent)\n",
    "    print(f\"\\nIntent: '{intent}'\")\n",
    "    print(f\"  Spatial ambiguity: {parser.has_spatial_ambiguity()}\")\n",
    "    print(f\"  Vague quantifiers: {parser.has_vague_quantifiers()}\")\n",
    "    print(f\"  Implicit I/O: {parser.has_implicit_io()}\")\n",
    "    print(f\"  Symmetry ambiguity: {parser.has_symmetry_ambiguity()}\")\n",
    "    if parser.extracted_values:\n",
    "        print(f\"  Extracted values: {parser.extracted_values}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 RuleEngine\n",
    "\n",
    "The RuleEngine evaluates requirements against all three rule families and determines what information is needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create empty requirements and evaluate\n",
    "requirements = ObjectRequirements()\n",
    "engine = RuleEngine(organ_type='liver')\n",
    "\n",
    "result = engine.evaluate(requirements, intent='dense liver network')\n",
    "\n",
    "print('RuleEngine Evaluation:')\n",
    "print('=' * 70)\n",
    "print(f\"Generation ready: {result.is_generation_ready}\")\n",
    "print(f\"\\nMissing fields ({len(result.missing_fields)}):\")\n",
    "for flag in result.missing_fields[:3]:\n",
    "    print(f\"  [{flag.severity}] {flag.message}\")\n",
    "print(f\"\\nAmbiguity flags ({len(result.ambiguity_flags)}):\")\n",
    "for flag in result.ambiguity_flags:\n",
    "    print(f\"  [{flag.severity}] {flag.message}\")\n",
    "print(f\"\\nProposed defaults ({len(result.proposed_defaults)}):\")\n",
    "for prop in result.proposed_defaults[:3]:\n",
    "    print(f\"  {prop.field}: {prop.value} ({prop.reason})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 QuestionPlanner\n",
    "\n",
    "The QuestionPlanner generates the minimal set of questions needed, ranked by rework cost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plan questions based on evaluation result\n",
    "planner = QuestionPlanner()\n",
    "questions = planner.plan(result, max_questions=4)\n",
    "\n",
    "print('Planned Questions (ranked by rework cost):')\n",
    "print('=' * 70)\n",
    "for i, q in enumerate(questions, 1):\n",
    "    default_str = f' [{q.default_value}]' if q.default_value else ''\n",
    "    print(f\"{i}. [{q.rework_cost.upper()}] {q.question_text}{default_str}\")\n",
    "    print(f\"   Field: {q.field}\")\n",
    "    print(f\"   Reason: {q.reason}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Resolution Strategy Comparison\n",
    "\n",
    "The rule engine employs a three-tier resolution strategy. More explicit user intents result in fewer questions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate how explicit values reduce questions\n",
    "explicit_intent = 'box 2x6x3 cm, diameter 1mm, 2 inlets, 1 outlet'\n",
    "vague_intent = 'dense branching network on the left side'\n",
    "\n",
    "for intent in [explicit_intent, vague_intent]:\n",
    "    parser = IntentParser(intent)\n",
    "    req = ObjectRequirements()\n",
    "    eng = RuleEngine()\n",
    "    res = eng.evaluate(req, intent)\n",
    "    qs = planner.plan(res, max_questions=4)\n",
    "    \n",
    "    print(f\"\\nIntent: '{intent}'\")\n",
    "    print(f\"  Extracted values: {len(parser.extracted_values)}\")\n",
    "    print(f\"  Ambiguities detected: {len(res.ambiguity_flags)}\")\n",
    "    print(f\"  Questions needed: {len(qs)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Dynamic Question Variance\n",
    "\n",
    "The workflow automatically detects the organ type from user descriptions and tailors questions accordingly for Groups C (Inlets/Outlets), D (Topology), and E (Geometry)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Organ Type Detection\n",
    "\n",
    "The system identifies organ type from keywords in the user's description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_intents = [\n",
    "    'liver vascular network',\n",
    "    'kidney with renal arteries',\n",
    "    'lung pulmonary tree',\n",
    "    'coronary arteries for heart',\n",
    "    'generic tubular structure',\n",
    "]\n",
    "print('Organ Detection Results:')\n",
    "print('-' * 50)\n",
    "for intent in test_intents:\n",
    "    organ = detect_organ_type(intent)\n",
    "    print(f\"{organ:8} <- {intent}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Tailored Questions by Organ Type\n",
    "\n",
    "Each organ type receives customized questions appropriate to its anatomical characteristics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Group C (Inlets/Outlets) - First Question by Organ Type:')\n",
    "print('=' * 60)\n",
    "for organ in ['liver', 'kidney', 'lung', 'heart', 'generic']:\n",
    "    q = get_tailored_questions(f'{organ} network')\n",
    "    group_c = q['C']\n",
    "    first_q = group_c['questions'][0]\n",
    "    print(f\"\\n{organ.upper()} ({group_c['name']}):\\n  Q: {first_q[1]}\\n  Default: {first_q[2]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Workflow States\n",
    "\n",
    "The workflow progresses through a defined sequence of states, from project initialization to final artifact export."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Workflow States:')\n",
    "for i, state in enumerate(WorkflowState, 1):\n",
    "    print(f\"{i:2}. {state.value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Question Groups (Reference)\n",
    "\n",
    "The following question groups are maintained for reference and backward compatibility. The rule engine (Section 3) is the recommended approach for requirements capture, as it asks only what is needed based on the current state of the specification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Question Groups:')\n",
    "for key, group in QUESTION_GROUPS.items():\n",
    "    print(f\"Group {key}: {group['name']} ({len(group['questions'])} questions)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Organ-Specific Question Variants\n",
    "\n",
    "These variants provide organ-specific phrasing for questions. The rule engine automatically detects organ type from user intent and applies appropriate variants to make the conversation more natural."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Organ-Specific Variants:')\n",
    "for organ, variants in ORGAN_QUESTION_VARIANTS.items():\n",
    "    print(f\"\\n{organ.upper()}: {variants['description']}\")\n",
    "    for g in [\"C\", \"D\", \"E\"]:\n",
    "        if g in variants:\n",
    "            print(f\"  Group {g}: {variants[g]['name']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Running the Workflow\n",
    "\n",
    "Launch the interactive workflow to generate organ structures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick start (uncomment to run):\n",
    "# context = run_single_agent_workflow(provider=PROVIDER, model=MODEL, api_key=API_KEY)\n",
    "print('Uncomment above to run interactive workflow')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Per-Object Folder Structure\n",
    "\n",
    "Each object in a project maintains a complete artifact history in a structured folder hierarchy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\"\"outputs/<project>/\n",
    "├── project.json\n",
    "└── objects/<object>/\n",
    "    ├── 00_intent/     (intent.txt, requirements_v001.json)\n",
    "    ├── 01_spec/       (spec_v001.json)\n",
    "    ├── 02_code/       (generate_v001.py)\n",
    "    ├── 03_outputs/    (network_v001.json)\n",
    "    ├── 04_mesh/       (mesh_v001_network.stl)\n",
    "    ├── 05_analysis/   (analysis_v001.json)\n",
    "    ├── 06_validation/ (validation_v001.json)\n",
    "    ├── 07_iterations/\n",
    "    └── 08_final/      (void.stl, manifest.json)\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Requirements Schema\n",
    "\n",
    "The requirements schema comprises nine sections that fully specify an organ structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sections = [\n",
    "    (\"1. Identity\", \"object_name, slug, version\"),\n",
    "    (\"2. Frame of Reference\", \"origin, axes, viewpoint, units\"),\n",
    "    (\"3. Domain\", \"type, size, center, margin\"),\n",
    "    (\"4. Inlets/Outlets\", \"positions, radii, directions\"),\n",
    "    (\"5. Topology Intent\", \"style, target_terminals, max_depth\"),\n",
    "    (\"6. Geometry Intent\", \"segment_length, tortuosity, branch_angle\"),\n",
    "    (\"7. Constraints\", \"min_radius, min_clearance, boundary_buffer\"),\n",
    "    (\"8. Embedding & Export\", \"domain, voxel_pitch, stl_units\"),\n",
    "    (\"9. Acceptance Criteria\", \"min_radius, terminals_range, watertight\"),\n",
    "]\n",
    "print('Requirements Schema:')\n",
    "for section, fields in sections:\n",
    "    print(f\"{section}: {fields}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated the following capabilities:\n",
    "\n",
    "| Topic | Description |\n",
    "|-------|-------------|\n",
    "| **Rule Engine** | Adaptive requirements capture with three rule families |\n",
    "| **Dynamic Variance** | Organ-specific question tailoring for liver, kidney, lung, heart |\n",
    "| **Workflow States** | Ten-step workflow from initialization to completion |\n",
    "| **Question Groups** | Seven groups (A-G) covering all specification aspects |\n",
    "| **Requirements Schema** | Nine-section schema for complete structure specification |\n",
    "| **Folder Structure** | Per-object artifact organization with versioning |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
